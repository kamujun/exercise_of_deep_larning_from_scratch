{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4章　ニューラルネットワークの学習\n",
    "\n",
    "ここでは学習とは訓練データから最適な重みパラメータの値を自動的に獲得することを指す。\n",
    "\n",
    "## 4.1 データから学習する\n",
    "ニューラルネットワークはデータから学習できる特徴がある。これは多数の重みパラメータを人力で設定する必要がなくなるため、有用である。\n",
    "\n",
    "### 4.1.1 データ駆動\n",
    "人にとって分かる規則性でもアルゴリズムで実現しようとすると難しい。アルゴリズムの考案ではなく、画像空特徴量を抽出したえパターンを学習させることで実現する。特徴量とはデータから重要なデータを的確に抽出できるように設計した変換器のことである。\n",
    "画像の特徴量は通常、ベクトルとして記述される。(コンピュータビジョン分野ではSIFTやSURF、HOGなどが挙げられる)。それらの特徴量を使って画像データをベクトルに変換し、機械学習で用いる識別器で学習を行なう。\n",
    "\n",
    "アルゴリズムを考える代わりに、問題に応じて適した特徴量を持ちいらなければ良い結果は得られない。(人の手によって特徴量を考える必要がある可能性)\n",
    "人力においても、機械学習と特徴量によるアプローチも人の手が介在していたが、ディープラーニングでは特徴量の選択自体も機械が学習を行なう。(「5」の認識であっても、「犬」の認識であってもアプローチ方法は変わらない)\n",
    "\n",
    "ニューラルネットワークは、対象とする問題に関係なくデータをそのまま生データとして「end-to-end」学習することができる。(生データの入力で目的の結果出力まで得られる)\n",
    "\n",
    "\n",
    "### 4.1.2 訓練データとテストデータ\n",
    "機械学習の問題では作成したモデルの汎化能力を正しく評価したい。そのため訓練データ(教師データ)とテストデータを分離する。一つのデータセットだけで学習、評価を行なうとそのデータセットにしか対応できていないものの良い結果が得られたと誤認してしまう。特定のデータセットのみにだけ過度に適合した状態を過学習(overfitting)と呼ぶ。必ず避けなければ行けない状態。\n",
    "\n",
    "\n",
    "## 4.2 損失関数\n",
    "\n",
    "ニューラルネットワークの学習ではある指標で現在の状態を表す。損失関数(loss function)と呼ばれ、この指標を基準として最適な重みの探索を行なう。関数は任意のものが用いられるが、一般的には二乗和誤差や交差エントロピー誤差が用いられる。\n",
    "損失関数は教師データからどれだけ逸れているかを表す指標であり、小さくなればなるほど良い性能を示していると言える。\n",
    "\n",
    "### 4.2.1 二乗和誤差\n",
    "二乗和誤差は以下式で表される。\n",
    "\n",
    "$$\n",
    "E = \\frac{1}{2}\\sum(y_{k}-t_{k})^{2}\n",
    "$$\n",
    "\n",
    "$y_{k}$はニューラルネットワークの出力データ、$t_{k}$は教師データ、$k$はデータの次元数を表す。\n",
    "\n",
    "出力データはソフトマックス関数のの出力であり、確率と同義である。教師データは正解データのみ「1」、それ以外は「0」で格納されており「one-hot表現」と呼ばれる。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0975\n0.5975\n"
     ]
    }
   ],
   "source": [
    "# 2乗和誤差の実装\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def mean_squared_error(y, t):\n",
    "    return 0.5 * np.sum((y-t)**2)\n",
    "\n",
    "# 「2」が正解\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "# 「2」であると推定する場合(誤差が小さい)\n",
    "y_2 = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "\n",
    "print(mean_squared_error(np.array(y_2), np.array(t)))\n",
    "\n",
    "\n",
    "# 「7」であると推定する場合(誤差が大きい)\n",
    "y_7 = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "\n",
    "print(mean_squared_error(np.array(y_7), np.array(t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 交差エントロピー誤差\n",
    "\n",
    "損失関数として交差エントロピー誤差(cross entropy error)も多く用いられる。\n",
    "\n",
    "$$\n",
    "E = -\\sum_{k}t_{k}log\\;y_{k}\n",
    "$$\n",
    "\n",
    "logは体がeの自然対数($log_{e}$)を表す。$y_{k}$はニューラルネットワークの出力、$t_{k}$は正解ラベルとする(one-hot表現)。そのため、実質的には正解ラベルが1に対応する出力の自然対数のみを計算する。(正解ラベルのネットワーク出力が0.6の場合-log0.6=0.51、0.1の場合-log0.1=2.30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/smap3/PycharmProjects/exercise_of_deep_larning_from_scratch/env/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in log\n  \n/Users/smap3/PycharmProjects/exercise_of_deep_larning_from_scratch/env/lib/python3.6/site-packages/matplotlib/font_manager.py:1297: UserWarning: findfont: Font family ['IPAexGothic'] not found. Falling back to DejaVu Sans\n  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niMco2EVEPOb/AyA+knkoQrSdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106adf630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# データの作成\n",
    "x = np.arange(0, 1.0, 0.01)\n",
    "y = np.log(x)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自然対数をプロットすると上図のようになる。xが1の時にyが0となる。\n",
    "よって確率が上がれば上がるほど、誤差である自然対数は0に近づく。\n",
    "\n",
    "交差エントロピーを実装すると以下となる。\n",
    "np.logの計算時に微小値であるdeltaを加算している。np.log(0)の場合において無限小(-inf)となりエラーになることを防ぐためである。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.510825457099\n2.30258409299\n"
     ]
    }
   ],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t * np.log(y + delta))\n",
    "\n",
    "# 「2」が正解\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "# 「2」であると推定する場合(誤差が小さい)\n",
    "y_2 = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "print(cross_entropy_error(np.array(y_2), np.array(t)))\n",
    "\n",
    "# 「7」であると推定する場合(誤差が大きい)\n",
    "y_7 = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "print(cross_entropy_error(np.array(y_7), np.array(t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 ミニバッチ学習\n",
    "これまで算出した損失関数は一つの訓練データについて求めて、できるだけ小さくするようにパラメータを探そうとしていた。実際の学習では全ての訓練データを対象として損失関数を求め、パラメータを算出する必要がある。交差エントロピーの場合は以下式。($t_{nk}$はn個目のデータのk次元目の値を意味する。)\n",
    "\n",
    "$$\n",
    "E = - \\frac{1}{N} \\sum_{n}\\sum_{k}t_{nk} log \\;y_{nk}\n",
    "$$\n",
    "\n",
    "Nで割るのは訓練データ全ての平均誤差を算出するためであり、データ数に関係なく統一した指標として用いるためである。\n",
    "\n",
    "しかし、大量の訓練データの場合は計算に時間がかかってしまうため、データの中から一部を選び出して全体の近似として利用する。このような学習方法を「ミニバッチ学習」という。\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n(60000, 10)\n(10, 784)\n(10, 10)\n[12834 10781 37939 21439 40024 11118 27697 25948  8812 38193]\n"
     ]
    }
   ],
   "source": [
    "# ミニバッチ法の実装\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from src.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "    load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(t_train.shape)\n",
    "\n",
    "\n",
    "# 訓練データをランダムに10枚抜き出す\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 10\n",
    "\n",
    "# ミニバッチとして選出するインデックスを配列として取得\n",
    "batch_mask = np.random.choice(train_size, batch_size)\n",
    "\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]\n",
    "\n",
    "print(x_batch.shape)\n",
    "print(t_batch.shape)\n",
    "\n",
    "print(batch_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}